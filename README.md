# Awesome-Visual-Tracking
This repository aims to collect awesome visual tracking works, including algorithms and benchmarks. The goal is to provide a platform (like an informal review) for researchers to conveniently follow recently published as well as previous literature in the tracking community. Please note that, this repository focuses on the so-called `single object tracking`, including both 2D and 3D tracking tasks.


## Regarding this repository

* #### Why build this repository?
  
Visual tracking is a rapidly evolving field with a significant number of research papers proposed each year. To understand the most recent trends in visual tracking, we build this repository to collect the latest works (which are accepted or published; arXiv papers are not included now, but may be added later) so that researchers in this area can easily follow cutting-edge ideas and innovations in this community. 

* #### What will be included in this repository?

In this repository, we will focus on the bounding-box-based visual tracking, including `single modality visual tracking` (i.e., RGB tracking and LiDAR-based tracking) and `multi-modality visual tracking` (i.e., RGB-X tracking, with X being language/depth/event/thermal/LiDAR etc). Both tracking algorithm and benchmark papers will be collected.

* #### Where will you collect the tracking papers?

With numerous papers published on visual tracking each year, it is (almost) impossible to collect all the papers in this field. Hence, we will collect papers from major computer vision (e.g., CVPR/ICCV/ECCV) and machine learning (e.g., NeurIPS/ICLR/ICML) conferences because they usually represent the latest innovations in the tracking community. 

* #### How is your repository different from others?

* #### How will this repository be maintained and update?

## Updates

## Content



## Acknowledgements
